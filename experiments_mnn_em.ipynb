{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from utils.char_tokenizer import CharTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 05:54:09.104184: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-23 05:54:09.781857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30976 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:5b:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'current': 0, 'peak': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.get_memory_info(\"GPU:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(\"config.json\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>path</th>\n",
       "      <th>product_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desk small desk white desk desks computer desk...</td>\n",
       "      <td>cc/cc3664a2.jpg</td>\n",
       "      <td>DESK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mobile coverb07tg4lwrdamazon brand - solimo de...</td>\n",
       "      <td>4c/4c015ec6.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cellphonecoverb0856b3szqamazon brand - solimo ...</td>\n",
       "      <td>b9/b983774d.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wirebindb07yb3c3qbamazonbasics coil binding sp...</td>\n",
       "      <td>35/3595924e.jpg</td>\n",
       "      <td>OFFICE_PRODUCTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mobile coverb07vsn27mtcare of by puma men's me...</td>\n",
       "      <td>66/66f9dc3f.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157196</th>\n",
       "      <td>spray mopb07n13rptwamazon brand - solimo desig...</td>\n",
       "      <td>f2/f22aceeb.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157197</th>\n",
       "      <td>mobile coverb07tf1fnrjamazon brand - solimo de...</td>\n",
       "      <td>2f/2fbbde2c.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157198</th>\n",
       "      <td>back coverb0854fk2xramazon brand - solimo desi...</td>\n",
       "      <td>a6/a6ab33b4.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157199</th>\n",
       "      <td>mobile coverb07tg4j5g5amazon brand - solimo de...</td>\n",
       "      <td>5f/5ff1525e.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157200</th>\n",
       "      <td>mobile coverb07th329y4amazon brand - solimo de...</td>\n",
       "      <td>72/72e04ced.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157201 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description             path   \n",
       "0       desk small desk white desk desks computer desk...  cc/cc3664a2.jpg  \\\n",
       "1       mobile coverb07tg4lwrdamazon brand - solimo de...  4c/4c015ec6.jpg   \n",
       "2       cellphonecoverb0856b3szqamazon brand - solimo ...  b9/b983774d.jpg   \n",
       "3       wirebindb07yb3c3qbamazonbasics coil binding sp...  35/3595924e.jpg   \n",
       "4       mobile coverb07vsn27mtcare of by puma men's me...  66/66f9dc3f.jpg   \n",
       "...                                                   ...              ...   \n",
       "157196  spray mopb07n13rptwamazon brand - solimo desig...  f2/f22aceeb.jpg   \n",
       "157197  mobile coverb07tf1fnrjamazon brand - solimo de...  2f/2fbbde2c.jpg   \n",
       "157198  back coverb0854fk2xramazon brand - solimo desi...  a6/a6ab33b4.jpg   \n",
       "157199  mobile coverb07tg4j5g5amazon brand - solimo de...  5f/5ff1525e.jpg   \n",
       "157200  mobile coverb07th329y4amazon brand - solimo de...  72/72e04ced.jpg   \n",
       "\n",
       "               product_type  label  \n",
       "0                      DESK      1  \n",
       "1       CELLULAR_PHONE_CASE      1  \n",
       "2       CELLULAR_PHONE_CASE      1  \n",
       "3           OFFICE_PRODUCTS      1  \n",
       "4       CELLULAR_PHONE_CASE      0  \n",
       "...                     ...    ...  \n",
       "157196  CELLULAR_PHONE_CASE      0  \n",
       "157197  CELLULAR_PHONE_CASE      1  \n",
       "157198  CELLULAR_PHONE_CASE      1  \n",
       "157199  CELLULAR_PHONE_CASE      1  \n",
       "157200  CELLULAR_PHONE_CASE      1  \n",
       "\n",
       "[157201 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(config[\"data\"][\"path\"], \"data.csv\"))\n",
    "data = data.drop({\"Unnamed: 0\"}, axis=1)\n",
    "data['product_type'] = data['product_type.value']\n",
    "data = data[['description', 'path', 'product_type', 'label']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data[[\"path\"]] # two brackets for keeping the column name\n",
    "text = data[\"description\"]\n",
    "product_types = data[[\"product_type\"]]\n",
    "labels = data[[\"label\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157201, 1014)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = CharTokenizer(config[\"data\"][\"alphabet\"])\n",
    "text = tk.tokenize(text)\n",
    "text.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embedding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3188, 3187)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = tk.create_embedding_weights()\n",
    "weights.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import img_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 576)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_model = img_models.load(config[\"img_model\"])\n",
    "\n",
    "img_model.output_shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_models.create_embeddings_from(img_model, img, os.path.join(config[\"data\"][\"path\"], \"images/small\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(config[\"data\"][\"path\"], \"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_path, exist_ok=True)\n",
    "np.save(f\"{save_path}/img.npy\", img)\n",
    "np.save(f\"{save_path}/text.npy\", text)\n",
    "data.to_csv(f\"{save_path}/data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>path</th>\n",
       "      <th>product_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desk small desk white desk desks computer desk...</td>\n",
       "      <td>cc/cc3664a2.jpg</td>\n",
       "      <td>DESK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mobile coverb07tg4lwrdamazon brand - solimo de...</td>\n",
       "      <td>4c/4c015ec6.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cellphonecoverb0856b3szqamazon brand - solimo ...</td>\n",
       "      <td>b9/b983774d.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wirebindb07yb3c3qbamazonbasics coil binding sp...</td>\n",
       "      <td>35/3595924e.jpg</td>\n",
       "      <td>OFFICE_PRODUCTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mobile coverb07vsn27mtcare of by puma men's me...</td>\n",
       "      <td>66/66f9dc3f.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157196</th>\n",
       "      <td>spray mopb07n13rptwamazon brand - solimo desig...</td>\n",
       "      <td>f2/f22aceeb.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157197</th>\n",
       "      <td>mobile coverb07tf1fnrjamazon brand - solimo de...</td>\n",
       "      <td>2f/2fbbde2c.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157198</th>\n",
       "      <td>back coverb0854fk2xramazon brand - solimo desi...</td>\n",
       "      <td>a6/a6ab33b4.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157199</th>\n",
       "      <td>mobile coverb07tg4j5g5amazon brand - solimo de...</td>\n",
       "      <td>5f/5ff1525e.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157200</th>\n",
       "      <td>mobile coverb07th329y4amazon brand - solimo de...</td>\n",
       "      <td>72/72e04ced.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157201 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description             path   \n",
       "0       desk small desk white desk desks computer desk...  cc/cc3664a2.jpg  \\\n",
       "1       mobile coverb07tg4lwrdamazon brand - solimo de...  4c/4c015ec6.jpg   \n",
       "2       cellphonecoverb0856b3szqamazon brand - solimo ...  b9/b983774d.jpg   \n",
       "3       wirebindb07yb3c3qbamazonbasics coil binding sp...  35/3595924e.jpg   \n",
       "4       mobile coverb07vsn27mtcare of by puma men's me...  66/66f9dc3f.jpg   \n",
       "...                                                   ...              ...   \n",
       "157196  spray mopb07n13rptwamazon brand - solimo desig...  f2/f22aceeb.jpg   \n",
       "157197  mobile coverb07tf1fnrjamazon brand - solimo de...  2f/2fbbde2c.jpg   \n",
       "157198  back coverb0854fk2xramazon brand - solimo desi...  a6/a6ab33b4.jpg   \n",
       "157199  mobile coverb07tg4j5g5amazon brand - solimo de...  5f/5ff1525e.jpg   \n",
       "157200  mobile coverb07th329y4amazon brand - solimo de...  72/72e04ced.jpg   \n",
       "\n",
       "               product_type  label  \n",
       "0                      DESK      1  \n",
       "1       CELLULAR_PHONE_CASE      1  \n",
       "2       CELLULAR_PHONE_CASE      1  \n",
       "3           OFFICE_PRODUCTS      1  \n",
       "4       CELLULAR_PHONE_CASE      0  \n",
       "...                     ...    ...  \n",
       "157196  CELLULAR_PHONE_CASE      0  \n",
       "157197  CELLULAR_PHONE_CASE      1  \n",
       "157198  CELLULAR_PHONE_CASE      1  \n",
       "157199  CELLULAR_PHONE_CASE      1  \n",
       "157200  CELLULAR_PHONE_CASE      1  \n",
       "\n",
       "[157201 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f\"{save_path}/data.csv\")\n",
    "data = data.drop({\"Unnamed: 0\"}, axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157201, 576)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.load(f\"{save_path}/img.npy\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157201, 1014)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = np.load(f\"{save_path}/text.npy\")\n",
    "text.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `stratify` parameter of `sklearn.model_selection.train_test_split()`, we need to select all product instances which appear more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"product_type_count\"] = data.groupby([\"product_type\"])[\"product_type\"].transform(\"count\")\n",
    "\n",
    "data = data[data[\"product_type_count\"] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update both columns\n",
    "product_types = data[[\"product_type\"]]\n",
    "\n",
    "labels = data[[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, labels_train, labels_test = train_test_split(data, labels, stratify=product_types, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = img[train.index]\n",
    "img_test = img[test.index]\n",
    "\n",
    "text_train = text[train.index]\n",
    "text_test = text[test.index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Char CNN config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.char_cnn_zhang import CharCNNZhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_cnn_config = {\n",
    "    \"input_size\": config[\"data\"][\"input_size\"],\n",
    "    \"embedding_size\": len(tk.word_index),\n",
    "    \"conv_layers\": config[\"char_cnn_zhang\"][\"conv_layers\"],\n",
    "    \"fully_connected_layers\": config[\"char_cnn_zhang\"][\"fully_connected_layers\"],\n",
    "    \"output_size\": config[\"char_cnn_zhang\"][\"output_size\"],\n",
    "    \"embedding_weights\": weights\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt_model = CharCNNZhang(**char_cnn_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build MNN-EM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mnn_em import MNNEM\n",
    "from utils.eval import create_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnn_em = MNNEM(img_input_size=img_model.layers[-1].output_shape[1],\n",
    "              img_conv_layers=config[\"mnn_em\"][\"img_conv_layers\"],\n",
    "              txt_input_size=config[\"data\"][\"input_size\"],\n",
    "              txt_conv_layers=config[\"mnn_em\"][\"txt_conv_layers\"],\n",
    "              txt_weights=weights,\n",
    "              char_cnn_config=char_cnn_config,\n",
    "              combined_conv_layers=config[\"mnn_em\"][\"combined_conv_layers\"],\n",
    "              learning_rate=config[\"mnn_em\"][\"training\"][\"learning_rate\"],\n",
    "              metrics=create_metrics(config[\"mnn_em\"][\"training\"][\"metrics\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Text_Input (InputLayer)        [(None, 1014)]       0           []                               \n",
      "                                                                                                  \n",
      " Image_Input (InputLayer)       [(None, 576)]        0           []                               \n",
      "                                                                                                  \n",
      " Character_Level_CNN (Functiona  (None, 2048)        29180700    ['Text_Input[0][0]']             \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " Image_FC_1 (Dense)             (None, 1024)         590848      ['Image_Input[0][0]']            \n",
      "                                                                                                  \n",
      " Text_FC_1 (Dense)              (None, 1024)         2098176     ['Character_Level_CNN[0][0]']    \n",
      "                                                                                                  \n",
      " Image_FC_last (Dense)          (None, 512)          524800      ['Image_FC_1[0][0]']             \n",
      "                                                                                                  \n",
      " Text_FC_last (Dense)           (None, 512)          524800      ['Text_FC_1[0][0]']              \n",
      "                                                                                                  \n",
      " Image_Batch_Normalization (Bat  (None, 512)         2048        ['Image_FC_last[0][0]']          \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " Text_Batch_Normalization (Batc  (None, 512)         2048        ['Text_FC_last[0][0]']           \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " Element-wise_Multiplication (M  (None, 512)         0           ['Image_Batch_Normalization[0][0]\n",
      " ultiply)                                                        ',                               \n",
      "                                                                  'Text_Batch_Normalization[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " Combined_FC_1 (Dense)          (None, 512)          262656      ['Element-wise_Multiplication[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " Combined_FC_2 (Dense)          (None, 256)          131328      ['Combined_FC_1[0][0]']          \n",
      "                                                                                                  \n",
      " Sigmoid (Dense)                (None, 1)            257         ['Combined_FC_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33,317,661\n",
      "Trainable params: 33,315,613\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnn_em.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(mnn_em.model, rankdir=\"TB\", show_layer_activations=True, show_shapes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval import create_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = create_callbacks(\n",
    "    callbacks_list=config[\"mnn_em\"][\"training\"][\"callbacks\"],\n",
    "    model_name=config[\"mnn_em\"][\"name\"],\n",
    "    img_model_name=img_model.name,\n",
    "    optimizer_name=config[\"mnn_em\"][\"training\"][\"optimizer\"],\n",
    "    learning_rate=config[\"mnn_em\"][\"training\"][\"learning_rate\"],\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 05:54:25.373565: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4780/7956 [=================>............] - ETA: 3:17 - loss: 1.4711 - recall: 0.9256 - precision: 0.8547 - binary_accuracy: 0.8710 - cosine_similarity: 0.5568"
     ]
    }
   ],
   "source": [
    "history = mnn_em.model.fit(\n",
    "    x=[img_train, text_train],\n",
    "    y=labels_train,\n",
    "    epochs=config[\"mnn_em\"][\"training\"][\"epochs\"],\n",
    "    validation_split=config[\"mnn_em\"][\"training\"][\"validation_split\"],\n",
    "    batch_size=config[\"mnn_em\"][\"training\"][\"batch_size\"], \n",
    "callbacks=callbacks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
